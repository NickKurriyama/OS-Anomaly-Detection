import json
import joblib
import os
import streamlit as st
import pandas as pd

# =====================================================
# 1. C·∫§U H√åNH & T·∫¢I MODEL
# =====================================================
MODEL_PATH = "xgboost_model.pkl"
SCALER_PATH = "z_scaler.pkl"
FEATURE_COLS_PATH = "feature_columns.json"
SCALE_COLS = ["argsNum", "returnValue"]

@st.cache_resource
def load_artifacts():
    try:
        if not os.path.exists(MODEL_PATH):
            return None, None, f"Kh√¥ng t√¨m th·∫•y file {MODEL_PATH}"
        model = joblib.load(MODEL_PATH)
        scaler = joblib.load(SCALER_PATH)
        with open(FEATURE_COLS_PATH, "r") as f:
            feature_cols = json.load(f)
        return model, scaler, feature_cols
    except Exception as e:
        return None, None, str(e)

model, scaler, FEATURE_COLS = load_artifacts()

# =====================================================
# 2. H√ÄM X·ª¨ L√ù L·ªåC TI·∫æN TR√åNH (V√íNG L·∫∂P)
# =====================================================
def scan_processes(df_input):
    """
    Duy·ªát qua t·ª´ng d√≤ng trong file test, d·ª± ƒëo√°n v√† l·ªçc ra danh s√°ch l·ªói
    """
    anomalies = []
    normal_count = 0
    
    # ƒê·∫£m b·∫£o dataframe c√≥ ƒë·ªß c√°c c·ªôt c·∫ßn thi·∫øt, thi·∫øu th√¨ b√π b·∫±ng 0
    for col in FEATURE_COLS:
        if col not in df_input.columns:
            df_input[col] = 0

    # L·∫•y d·ªØ li·ªáu theo ƒë√∫ng th·ª© t·ª± Feature model y√™u c·∫ßu
    X_raw = df_input[FEATURE_COLS].copy()
    
    # Scale d·ªØ li·ªáu h√†ng lo·∫°t ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô (thay v√¨ l·∫∑p t·ª´ng d√≤ng ƒë·ªÉ scale)
    X_scaled = X_raw.copy()
    X_scaled[SCALE_COLS] = scaler.transform(X_scaled[SCALE_COLS])
    
    # D·ª± ƒëo√°n to√†n b·ªô
    predictions = model.predict(X_scaled)
    
    # N·∫øu model c√≥ predict_proba th√¨ l·∫•y x√°c su·∫•t
    probs = [None] * len(predictions)
    try:
        probs = model.predict_proba(X_scaled)[:, 1]
    except:
        pass

    # V√≤ng l·∫∑p duy·ªát qua k·∫øt qu·∫£ ƒë·ªÉ ph√¢n lo·∫°i
    for i in range(len(predictions)):
        if predictions[i] == 1:
            # L∆∞u l·∫°i th√¥ng tin ti·∫øn tr√¨nh b·ªã l·ªói
            # Gi·∫£ s·ª≠ file test c√≥ c·ªôt 'name' ho·∫∑c 'pid', n·∫øu kh√¥ng c√≥ s·∫Ω b√°o 'Unknown'
            proc_info = {
                "T√™n": df_input.iloc[i].get("name", "Unknown"),
                "PID": df_input.iloc[i].get("pid", "N/A"),
                "M·ª©c ƒë·ªô r·ªßi ro": f"{probs[i]:.2%}" if probs[i] is not None else "N/A"
            }
            # Th√™m c√°c ch·ªâ s·ªë ƒë·∫∑c tr∆∞ng v√†o ƒë·ªÉ xem l√Ω do l·ªói
            for col in FEATURE_COLS:
                proc_info[col] = df_input.iloc[i][col]
            
            anomalies.append(proc_info)
        else:
            normal_count += 1
            
    return pd.DataFrame(anomalies), normal_count

# =====================================================
# 3. GIAO DI·ªÜN CH√çNH
# =====================================================
st.set_page_config(page_title="Batch Anomaly Detector", layout="wide", page_icon="üõ°Ô∏è")

st.title("üõ°Ô∏è Batch Process Security Scanner")
st.caption("T·∫£i l√™n file d·ªØ li·ªáu test ƒë·ªÉ m√¥ h√¨nh t·ª± ƒë·ªông qu√©t v√† l·ªçc ti·∫øn tr√¨nh ƒë·ªôc h·∫°i")

# Sidebar: H∆∞·ªõng d·∫´n file m·∫´u
with st.sidebar:
    st.header("üìÇ H∆∞·ªõng d·∫´n file Test")
    st.write("File c·∫ßn c√≥ c√°c c·ªôt:")
    st.code(", ".join(FEATURE_COLS))
    st.info("H·ªá th·ªëng s·∫Ω l·∫∑p qua t·ª´ng ti·∫øn tr√¨nh ƒë·ªÉ ph√¢n t√≠ch.")

# Giao di·ªán t·∫£i File
uploaded_file = st.file_uploader("Ch·ªçn file d·ªØ li·ªáu (CSV ho·∫∑c Excel)", type=["csv", "xlsx"])

if uploaded_file is not None:
    # ƒê·ªçc d·ªØ li·ªáu
    try:
        if uploaded_file.name.endswith('.csv'):
            df_test = pd.read_csv(uploaded_file)
        else:
            df_test = pd.read_excel(uploaded_file)
        
        st.write(f"üìä ƒê√£ t·∫£i l√™n **{len(df_test)}** ti·∫øn tr√¨nh.")
        
        if st.button("üöÄ B·∫Øt ƒë·∫ßu qu√©t h·ªá th·ªëng"):
            with st.spinner('ƒêang ch·∫°y v√≤ng l·∫∑p ki·ªÉm tra t·ª´ng ti·∫øn tr√¨nh...'):
                df_anomalies, normal_count = scan_processes(df_test)
            
            # Hi·ªÉn th·ªã k·∫øt qu·∫£ t·ªïng quan b·∫±ng c·ªôt
            st.divider()
            c1, c2, c3 = st.columns(3)
            c1.metric("T·ªïng s·ªë qu√©t", len(df_test))
            c2.metric("Ti·∫øn tr√¨nh B√¨nh th∆∞·ªùng", normal_count)
            c3.metric("Ti·∫øn tr√¨nh B·∫•t th∆∞·ªùng", len(df_anomalies), delta_color="inverse")

            # Hi·ªÉn th·ªã danh s√°ch b·ªã l·ªói
            if not df_anomalies.empty:
                st.error(f"üö® Ph√°t hi·ªán {len(df_anomalies)} ti·∫øn tr√¨nh c√≥ d·∫•u hi·ªáu nguy hi·ªÉm!")
                st.subheader("üìã Danh s√°ch ƒëen (Blacklist) ƒë√£ l·ªçc:")
                
                # Highlight c√°c d√≤ng l·ªói
                st.dataframe(df_anomalies.style.background_gradient(cmap='Reds', subset=['M·ª©c ƒë·ªô r·ªßi ro'] if "M·ª©c ƒë·ªô r·ªßi ro" in df_anomalies.columns else []))
                
                # Cho ph√©p t·∫£i v·ªÅ k·∫øt qu·∫£ l·ªói
                csv = df_anomalies.to_csv(index=False).encode('utf-8')
                st.download_button("üì• T·∫£i danh s√°ch l·ªói (.csv)", csv, "detected_anomalies.csv", "text/csv")
            else:
                st.success("‚úÖ Tuy·ªát v·ªùi! Kh√¥ng ph√°t hi·ªán ti·∫øn tr√¨nh n√†o b·∫•t th∆∞·ªùng trong file n√†y.")

    except Exception as e:
        st.error(f"L·ªói khi x·ª≠ l√Ω file: {e}")

else:
    # Giao di·ªán khi ch∆∞a t·∫£i file
    st.info("Vui l√≤ng t·∫£i l√™n file d·ªØ li·ªáu test ƒë·ªÉ b·∫Øt ƒë·∫ßu qu√° tr√¨nh l·ªçc.")
    # Hi·ªÉn th·ªã v√≠ d·ª• c·∫•u tr√∫c d·ªØ li·ªáu model c·∫ßn
    st.subheader("V√≠ d·ª• c·∫•u tr√∫c d·ªØ li·ªáu h·ª£p l·ªá:")
    example_data = pd.DataFrame([[0, 0, 1, 0, 0, 0]], columns=FEATURE_COLS)
    st.table(example_data)
